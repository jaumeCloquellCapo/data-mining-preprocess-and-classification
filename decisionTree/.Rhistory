pwd
a <- 2
a * 2
# Librerias R
library(rpart)
library(rstudioapi)
library(tree)
library(rJava)
library(partykit)
library(dplyr)
# Librerias R
library(rpart)
library(rstudioapi)
library(tree)
library(rJava)
library(partykit)
install.packages("partykit")
# Librerias R
library(rpart)
library(rstudioapi)
library(tree)
library(rJava)
library(partykit)
library(dplyr)
# Definimos el path de donde estemos trabajando.
setwd(dirname(getActiveDocumentContext()$path))
getwd()
dirname(getActiveDocumentContext()$path
)
setwd("/home/jaime/Escritorio/Máster/DataMining/decisionTree")
# Librerias propias
source("preprocess/lecturaDatos.R")
source("preprocess/discretizacion.R")
source("preprocess/NAs.R")
source("preprocess/noise.R")
#Lectura de datos
dataset <- readData(files = c("train.csv", "test.csv"))
str(dataset$train)
dim(dataset$train)
dim(dataset$train)[2]
#Lectura de datos
dataset <- readData(files = c("train.csv", "test.csv"))
# Tatamiento de los missign Values
dataset$train <- delete_NA(dataset$train)
#Se aplica el centrado y escalado sobre el conjunto de datos, una vez eliminados los valores perdidos
dataset$test <- caret::preProcess(dataset$test[, -c(dim(dataset$train)[2] - 1)],method=c("center","scale"))
str(dataset$test)
#Lectura de datos
dataset <- readData(files = c("train.csv", "test.csv"))
# Numero de Missing values
dataset$train %>% select(everything()) %>% summarise_all(funs(sum(is.na(.))))
# Tatamiento de los missign Values
dataset$train <- delete_NA(dataset$train)
#Se aplica el centrado y escalado sobre el conjunto de datos, una vez eliminados los valores perdidos
valoresPreprocesados <- caret::preProcess(dataset$test[, -c(dim(dataset$train)[2] - 1)],method=c("center","scale"))
valoresTransformados <- predict(valoresPreprocesados,dataset$test[, -c(dim(dataset$train)[2] - 1)])
str(valoresTransformados)
# Numero de Missing values
dataset$train %>% select(everything()) %>% summarise_all(funs(sum(is.na(.))))
# Tatamiento de los missign Values
dataset$train <- delete_NA(dataset$train)
#Se aplica el centrado y escalado sobre el conjunto de datos, una vez eliminados los valores perdidos
valoresPreprocesados <- caret::preProcess(dataset$test[, -c(dim(dataset$train)[2] - 1)],method=c("center","scale"))
dataset$test[, -c(dim(dataset$train)[2] - 1)] <- predict(valoresPreprocesados,dataset$test[, -c(dim(dataset$train)[2] - 1)])
str(dataset$test)
#Lectura de datos
dataset <- readData(files = c("train.csv", "test.csv"))
# Numero de Missing values
dataset$train %>% select(everything()) %>% summarise_all(funs(sum(is.na(.))))
# Tatamiento de los missign Values
dataset$train <- delete_NA(dataset$train)
#Se aplica el centrado y escalado sobre el conjunto de datos, una vez eliminados los valores perdidos
valoresPreprocesados <- caret::preProcess(dataset$test[, -c(dim(dataset$train)[2] - 1)],method=c("center","scale"))
dataset$train[, -c(dim(dataset$train)[2] - 1)] <- predict(valoresPreprocesados,dataset$train[, -c(dim(dataset$train)[2] - 1)])
str(dataset$train)
summary(dataset$train)
install.packages("mlbench")
install.packages("FSelector")
?random.forest.importance
source("selectorVariables/NAs.R")
source("preprocess/selectorVariables.R")
?sourceDirectory
install.packages("R.utils")
library(R.utils)
sourceDirectory("preprocess")
# Librerias R
library(rpart)
library(rstudioapi)
library(tree)
library(rJava)
library(partykit)
library(dplyr)
library(R.utils)
# Definimos el path de donde estemos trabajando.
setwd(dirname(getActiveDocumentContext()$path))
sourceDirectory("preprocess")
#Lectura de datos
dataset <- readData(files = c("train.csv", "test.csv"))
?sourceDirectory
list.files("preprocess")
for (files in list.files("preprocess")) {
source(file)
}
list.files("preprocess")
list.files("preprocess")[2]
for (files in list.files("preprocess")) {
source(file)
}
# Definimos el path de donde estemos trabajando.
setwd(dirname(getActiveDocumentContext()$path))
files <- list.files("preprocess")
files
for (files in files) {
source(file)
}
for (files in files) {
file
#source(file)
}
files <- list.files("preprocess")
for (file in files) {
print(file)
#source(file)
}
files <- list.files("preprocess")
for (file in files) {
print(file)
source(file)
}
paste()
?paste
for (file in files) {
source(paste("preprocess", file))
}
files <- list.files("preprocess")
for (file in files) {
source(paste("preprocess/", file))
}
paste("preprocess/", "a", collapse = null, sep = ""
)
paste("preprocess/", "a", collapse = null, sep = "")
paste(c("preprocess/","a"), collapse = null, sep = "")
paste(c("preprocess/","a"), collapse = null, sep = "")
paste("1st", "2nd", "3rd", collapse = ", ")
paste("a/", "w", "3rd", collapse = ", ")
paste("a/", "w", "3rd", collapse = NULL)
paste("a/", "w", "3rd", collapse = NULL, sep = "")
source(paste("preprocess/", file, collapse = NULL, sep = "") ))
for (file in files) {
source(paste("preprocess/", file, collapse = NULL, sep = "") ))
}
files <- list.files("preprocess")
for (file in files) {
source(paste("preprocess/", file, collapse = NULL, sep = ""))
}
# Librerias propias
files <- list.files("preprocess")
for (file in files) {
source(paste("preprocess/", file, collapse = NULL, sep = ""))
}
#Lectura de datos
dataset <- readData(files = c("train.csv", "test.csv"))
# Numero de Missing values
dataset$train %>% select(everything()) %>% summarise_all(funs(sum(is.na(.))))
# Tatamiento de los missign Values
dataset$train <- delete_NA(dataset$train)
cat("Datos completos: ",completos, " e incompletos: ",incompletos,"\n")
# Definimos el path de donde estemos trabajando.
setwd(dirname(getActiveDocumentContext()$path))
# Librerias propias
files <- list.files("preprocess")
for (file in files) {
source(paste("preprocess/", file, collapse = NULL, sep = ""))
}
install.packages("mice")
paste("a/", "w", "3rd", collapse = NULL, sep = "")
format(Sys.time(), "%a %b %d %X %Y")
timestamp <- format(Sys.time(), "%a %b %d %X %Y")
install.packages("mice")
paste(format(Sys.time(), "%d-%m-%Y"), ".csv", collapse = NULL, sep = "")
# Librerias R
library(rpart)
library(rstudioapi)
library(tree)
library(rJava)
library(partykit)
library(dplyr)
# Definimos el path de donde estemos trabajando.
setwd(dirname(getActiveDocumentContext()$path))
# Librerias propias
files <- list.files("preprocess")
for (file in files) {
source(paste("preprocess/", file, collapse = NULL, sep = ""))
}
#Lectura de datos
dataset <- readData(files = c("train.csv", "test.csv"))
# Numero de Missing values
dataset$train %>% select(everything()) %>% summarise_all(funs(sum(is.na(.))))
completos <- mice::ncc(dataset$train)
incompletos <- mice::nic(dataset$train)
cat("Datos completos: ",completos, " e incompletos: ",incompletos,"\n")
dim(dataset$train)
completos + incompletos
resultados <- mvoutlier::uni.plot(dataset$train)
install.packages("mvoutlier")
library("mvoutlier", lib.loc="~/R/x86_64-pc-linux-gnu-library/3.4")
resultados <- mvoutlier::uni.plot(dataset$train)
resultados <- mvoutlier::uni.plot(dataset$train[,c(1:5)])
resultados <- mvoutlier::uni.plot(dataset$train[,c(1:4)])
resultados <- mvoutlier::uni.plot(dataset$train[,1])
str(dataset$train)
resultados <- mvoutlier::uni.plot(dataset$train[,1])
resultados <- mvoutlier::uni.plot(dataset$train[,c(1,2)])
# Librerias R
library(rpart)
library(rstudioapi)
library(tree)
library(rJava)
library(partykit)
library(dplyr)
# Definimos el path de donde estemos trabajando.
setwd(dirname(getActiveDocumentContext()$path))
# Librerias propias
files <- list.files("preprocess")
for (file in files) {
source(paste("preprocess/", file, collapse = NULL, sep = ""))
}
#Lectura de datos
dataset <- readData(files = c("train.csv", "test.csv"))
# Numero de Missing values
dataset$train %>% select(everything()) %>% summarise_all(funs(sum(is.na(.))))
# Definimos el path de donde estemos trabajando.
setwd(dirname(getActiveDocumentContext()$path))
# Librerias propias
files <- list.files("preprocess")
for (file in files) {
source(paste("preprocess/", file, collapse = NULL, sep = ""))
}
#Lectura de datos
dataset <- readData(files = c("train.csv", "test.csv"))
# Numero de Missing values
dataset$train %>% select(everything()) %>% summarise_all(funs(sum(is.na(.))))
# Tatamiento de los missign Values
dataset$train <- delete_NA(dataset$train)
# TDetección outliers
dataset$train <- delete_ruidoCVCF(dataset$train)
str(dataset$train)
# construye el modelo
library(party)
install.packages("party")
# construye el modelo
library(party)
library(caret)
ct <- ctree(C~., dataset$train)
# se realiza la prediccion
testPred <- predict(ct, newdata = dataset$test)
results <- table(testPred, dataset$test$C)
dataset$test
results <- table(testPred, dataset$test)
results <- table(testPred, dataset$train$C)
# se suman los valores de la diagonal
sumDiag <- sum(diag(results))
# se suman todos los valores de la matriz
sumTotal <- sum(results)
# se calcula el porcentaje de aciertos
fiabilidad <- sumDiag/sumTotal
# Se calcula el error
error <- 1-fiabilidad
# tambien pueden estimarse las probabilidades de asignacion
# de cada instancias a cada clase
probabilidades <- predict(ct, testing, type="prob")
ct <- ctree(C~., dataset$train)
print(ct)
plot(ct)
# se realiza la prediccion
testPred <- predict(ct, dataset$test)
testPred
ct <- ctree(C~., dataset$train)
print(ct)
plot(ct)
# se realiza la prediccion
testPred <- predict(ct, dataset$test)
results <- table(testPred, dataset$train$C)
model
ct <- ctree(C~., dataset$train)
print(ct)
plot(ct)
# se realiza la prediccion
model <- predict(ct, dataset$test)
model
str(model)
model[1]
model[2]
model[3]
dim(dataset$test)
head(model)
head(dataset$test)
c(1:3919)
dim(dataset$test)
data_frame(1:dim(dataset$test)[1], model)
# create a dataframe with our results
my_submission <- data.frame(ids, predictModel)
# create a dataframe with our results
my_submission <- tibble(ids, predictModel)
tibble(1:dim(dataset$test)[1], model)
witeData(1:dim(dataset$test)[1], model)
my_submission <- tibble(ids, predictModel)
1:dim(dataset$test)[1]
dim(dataset$test)[1]
witeData(1:dim(dataset$test)[1], model, path = "results/")
witeData(1:dim(dataset$test)[1], model, path = "results/")
#predictModel <- predict(model, newdata = test)
#ids <- dataset$test$id
witeData <- function (ids, predictModel, path = "") {
# create a dataframe with our results
my_submission <- tibble(ids, predictModel)
write.csv(my_submission, paste(path, format(Sys.time(), "%d-%m-%Y"), ".csv", collapse = NULL, sep = "", row.names = FALSE))
}
witeData(1:dim(dataset$test)[1], model, path = "results/")
#predictModel <- predict(model, newdata = test)
#ids <- dataset$test$id
witeData <- function (ids, predictModel, path = "") {
# create a dataframe with our results
my_submission <- tibble(ids, predictModel)
write.csv(my_submission, paste(path, format(Sys.time(), "%d-%m-%Y"), ".csv", collapse = NULL, sep = "", row.names = FALSE, col.names=FALSE))
}
witeData(1:dim(dataset$test)[1], model, path = "results/")
tibble(1:dim(dataset$test)[1], model)
#predictModel <- predict(model, newdata = test)
#ids <- dataset$test$id
witeData <- function (ids, predictModel, path = "") {
# create a dataframe with our results
my_submission <- tibble(ids, predictModel)
write(my_submission, paste(path, format(Sys.time(), "%d-%m-%Y"), ".csv", collapse = NULL, sep = "", row.names = FALSE, col.names=FALSE))
}
witeData(1:dim(dataset$test)[1], model, path = "results/")
# Librerias propias
files <- list.files("preprocess")
# Librerias propias
for (file in list.files("preprocess")) {
source(paste("preprocess/", file, collapse = NULL, sep = ""))
}
# construye el modelo
library(party)
library(caret)
ct <- ctree(C~., dataset$train)
print(ct)
plot(ct)
# se realiza la prediccion
model <- predict(ct, dataset$test)
witeData(1:dim(dataset$test)[1], model, path = "results/")
witeData(1:dim(dataset$test)[1], model, path = "results/")
model
# Librerias propias
for (file in list.files("preprocess")) {
source(paste("preprocess/", file, collapse = NULL, sep = ""))
}
witeData(1:dim(dataset$test)[1], model, path = "results/")
my_submission <- tibble(1:dim(dataset$test)[1], model)
write(my_submission, paste("results/", format(Sys.time(), "%d-%m-%Y"), ".csv", sep = "", row.names = FALSE, col.names=FALSE))
write(my_submission, "results/hola.csv", sep = "", row.names = FALSE, col.names=FALSE)
write(my_submission, file = "results/hola.csv", sep = "", row.names = FALSE, col.names=FALSE)
write.table(my_submission, file = "results/hola.csv", sep = "", row.names = FALSE, col.names=FALSE)
write.table(my_submission, file = "results/hola.csv", sep = " ", row.names = FALSE, col.names=FALSE)
# Librerias propias
for (file in list.files("preprocess")) {
source(paste("preprocess/", file, collapse = NULL, sep = ""))
}
witeData(1:dim(dataset$test)[1], model, path = "results/")
# Librerias propias
for (file in list.files("preprocess")) {
source(paste("preprocess/", file, collapse = NULL, sep = ""))
}
witeData(1:dim(dataset$test)[1], model, path = "results/")
# Librerias propias
for (file in list.files("preprocess")) {
source(paste("preprocess/", file, collapse = NULL, sep = ""))
}
witeData(1:dim(dataset$test)[1], model, path = "results/")
witeData(1:dim(dataset$test)[1], model, path = "results/")
format(Sys.time(), "%a %b %d %X %Y")
# Librerias propias
for (file in list.files("preprocess")) {
source(paste("preprocess/", file, collapse = NULL, sep = ""))
}
witeData(1:dim(dataset$test)[1], model, path = "results/")
format(Sys.time(), "%X/%d-%m-%Y")
# Librerias propias
for (file in list.files("preprocess")) {
source(paste("preprocess/", file, collapse = NULL, sep = ""))
}
witeData(1:dim(dataset$test)[1], model, path = "results/")
witeData(1:dim(dataset$test)[1], model, path = "results/")
# Librerias propias
for (file in list.files("preprocess")) {
source(paste("preprocess/", file, collapse = NULL, sep = ""))
}
witeData(1:dim(dataset$test)[1], model, path = "results/")
# Librerias propias
for (file in list.files("preprocess")) {
source(paste("preprocess/", file, collapse = NULL, sep = ""))
}
witeData(1:dim(dataset$test)[1], model, path = "results/")
ct <- ctree(C~., dataset$train)
print(ct)
plot(ct)
# se realiza la prediccion
model <- predict(ct, dataset$test)
model
as.numeric(model)
# Definimos el path de donde estemos trabajando.
setwd(dirname(getActiveDocumentContext()$path))
# Librerias propias
for (file in list.files("preprocess")) {
source(paste("preprocess/", file, collapse = NULL, sep = ""))
}
#Lectura de datos
dataset <- readData(files = c("train.csv", "test.csv"))
dataset$train$C <- as.factor(dataset$train$C)
# Tatamiento de los missign Values
dataset$train <- delete_NA(dataset$train)
ct <- ctree(C~., dataset$train)
print(ct)
plot(ct)
# se realiza la prediccion
model <- predict(ct, dataset$test)
model
witeData(1:dim(dataset$test)[1], model, path = "results/")
# Librerias propias
for (file in list.files("preprocess")) {
source(paste("preprocess/", file, collapse = NULL, sep = ""))
}
witeData(1:dim(dataset$test)[1], model, path = "results/")
# Librerias R
library(rpart)
library(rstudioapi)
library(tree)
library(rJava)
library(partykit)
library(dplyr)
# Definimos el path de donde estemos trabajando.
setwd(dirname(getActiveDocumentContext()$path))
#Lectura de datos
dataset <- readData(files = c("train.csv", "test.csv"))
dataset$train$C <- as.factor(dataset$train$C)
# Numero de Missing values
dataset$train %>% select(everything()) %>% summarise_all(funs(sum(is.na(.))))
#Discretizamos las variables continuas con modelos no supervisados
dataset$train[,1] <- myDiscretization(dataset$train[,1], method = 2)
# Librerias propias
for (file in list.files("preprocess")) {
source(paste("preprocess/", file, collapse = NULL, sep = ""))
}
myDiscretization(dataset$train[,1], method = 2)
# Librerias propias
for (file in list.files("preprocess")) {
source(paste("preprocess/", file, collapse = NULL, sep = ""))
}
myDiscretization(dataset$train[,1], method = 2)
myDiscretization(dataset$train, method = 2)
# Librerias propias
for (file in list.files("preprocess")) {
source(paste("preprocess/", file, collapse = NULL, sep = ""))
}
myDiscretization(dataset$train, method = 2)
source('~/Máster/DataMining/decisionTree/DecicisionTree.R')
install.packages("mice")
library(mice)
md.pattern(dataset$train)
prodNA(dataset$train, noNA = 0.1)
install.packages("VIM")
?aggr
aggr_plot <- aggr(dataset$train, col=c('navyblue','red'), numbers=TRUE, sortVars=TRUE, labels=names(dataset$train), cex.axis=.7, gap=3, ylab=c("Histogram of missing data","Pattern"))
library(VIM)
aggr_plot <- aggr(dataset$train, col=c('navyblue','red'), numbers=TRUE, sortVars=TRUE, labels=names(dataset$train), cex.axis=.7, gap=3, ylab=c("Histogram of missing data","Pattern"))
mice(dataset$train,m=5,maxit=50,meth='pmm',seed=500)
tempData <- mice(dataset$train,m=5,maxit=50,meth='pmm',seed=500)
xyplot(tempData,C ~ .,pch=18,cex=1)
?xyplot
densityplot(tempData)
imputed_Data <- mice(dataset$train,m=5,maxit=50,meth='pmm',seed=500)
summary(imputed_Data)
complete(imputed_Data,2)
dataset$train <- complete(imputed_Data,2)
ct <- ctree(C~., dataset$train)
# construye el modelo
library(party)
library(caret)
ct <- ctree(C~., dataset$train)
print(ct)
plot(ct)
# se realiza la prediccion
model <- predict(ct, dataset$test)
witeData(1:dim(dataset$test)[1], model, path = "predictions/")
# Librerias propias
for (file in list.files("preprocess")) {
source(paste("preprocess/", file, collapse = NULL, sep = ""))
}
# Tatamiento de los missign Values
dataset$train <- NAs::na.mice(dataset$train)
# Tatamiento de los missign Values
dataset$train <- na.mice(dataset$train)
install.packages("missForest")
?prodNA
library(missForest)
?prodNA
