---
title: "DecisiónTree"
output: html_document
---

```{r setup, include=FALSE}
library(tree)
library(rpart)
library(rstudioapi)
library(tree)
library(rJava)
library(partykit)
library(dplyr)
library(party)
library(caret)
library(ipred)
library(RWeka)
library(randomForest)
library(gbm)
#https://github.com/armijoalb/Master-Ciencias-de-Datos-UGR/blob/master/Miner%C3%ADa%20de%20datos.%20Preprocesamiento%20y%20clasificacion/practicas456/clasificacion/kaggle_arboles.Rmd

#https://github.com/armijoalb/Master-Ciencias-de-Datos-UGR/blob/master/Miner%C3%ADa%20de%20datos.%20Preprocesamiento%20y%20clasificacion/preprocesamiento.pdf

# Definimos el path de donde estemos trabajando.
setwd(dirname(getActiveDocumentContext()$path))

# Librerias propias
for (file in list.files("preprocess")) {
  source(paste("preprocess/", file, collapse = NULL, sep = ""))
}
knitr::opts_chunk$set(echo = TRUE)
```


## Load Data
```{r}
#Lectura de datos
original.dataset <- readData()
#original.dataset$train[,-1] <- scale(original.dataset$train[,-1])
#original.dataset$test[,-1] <- scale(original.dataset$test[,-1])

train <- original.dataset$train
test <- original.dataset$test
#train$C <- as.factor(train$C)
```


# 1. Definición del dataset 


# 2. Proceso exploratorio y pre-procesado

El capítulo comienza detallando el proceso exploratorio inicial para continuar con el grueso de la memoria, la especificación de los procesos de pre-procesado llevados a cabo y la solución final aportada.

## 2.1 Proceso exploratorio

En esta sección detallamos el proceso exploratorio seguido para obtener más información del problema y de los datos que tenemos entre manos. Los pasos seguidos en este proceso serían:

### 2.1.1 Estudio de los datos y dimensiones

El primer paso para enfrentarnos a los datos era conocer la dimensionalidad y el tipo de datos. Por ello, hicimos uso de los comandos describe y str, para comprobar como eran estos datos y sus distribuciones.

```{r}
head(train)
```

El conjunto de datos de entrenamiento está formado por 9144 observaciones con 51 variables además de la clase catalogada como C y que puede tomar dos valores distintos (0,1). Las variables de entrenamiento, tienen todas valores numéricos continuos.


### 2.1.2 Valores perdidos

Al usar estudiar las distribuciones de los datos en el punto anterior descubrimos la existencia de valores perdidos en todas las variables. Para ver si este problema era muy acentuado se creó una función que nos ofrece el número de valores perdidos de un dataset por variables con diversos estadísticos. Tras obtener estos valores se representaron gráficamente para ver cuantos eran estos valores perdidos en función de la variable y el conjunto de train (figura 3.1).

Este gráfico nos llevo a comprobar que los valores perdidos no siguen patrones sino que son valores perdidos que parecen haber sido añadidos aleatoriamente o pertenecer a fallos en la toma de datos. La variable X9, es la que tiene un mayor número de missing values, seguidos por X40 y X13. A pesar de todo, no existe una diferencia significativa entre ello.

```{r}
library(VIM)
library(finalfit)
aggr_plot <- aggr(train, numbers=TRUE, sortVars=TRUE, labels=names(train), cex.axis=.7, gap=3, ylab=c("Histogram of missing data Train","Pattern"), prop = T)
train %>% missing_plot()
```

La siguiente secuencia de acciones determina el porcentaje de variables con valores perdidos en una instancia. Este porcentaje sirve para descartar instancias en que el porcentaje supera un cierto límite. Como observamos en los resultados todas las instancias necesitan ser filtradas.

```{r}
library(parallel)
system.time(res1 <- apply(train, 1, function(x) sum(is.na(x))) / ncol(train) * 100)
cores <- detectCores()
cluster <- makeCluster(cores-2)
system.time(res2 <- parRapply(cluster, train, function(x) sum(is.na(x)))/ncol(train)*100)
names(res2) <- NULL
stopCluster(cluster)
mal <- (res1 > 5)
filtrados <- train[!mal,]
cat("Instancias archivo original: ",nrow(train)," instancias en filtrado: ",nrow(filtrados),"\n")

#writeData(filtrados, path = "datosFiltrados/", "datosFiltrados")
```


###  2.1.3 Correlaciones: 

El tener tantas variables  y tanta presencia de valores perdidos hizo interesante la obtención de correlaciones para comprobar si podemos eliminar variables en pos de otras o imputar los valores perdidos con los de otra variable muy correlada. Para ello, usamos la función corrplot. El resultado podemos verlo en la figura 3.4 y descubrimos que la variable x41 tiene correlacion de 1 con la x48 siendo una el resultado del producto de la otra.

```{r}
# Compruebo los valores perdidos mediante mi función
perdidosTrain <- valoresPerdidos(train)
perdidosTest <- valoresPerdidos(test)
variablesNumericas <- sapply(1:dim(train)[2], function(x) is.numeric(train[,x]))
correlaciones <- cor(train[-perdidosTrain$`Instancias con perdidos`,variablesNumericas])
correlacionesFuertes <- sapply(1:dim(correlaciones)[2], function(x) any(correlaciones[-x,x]>0.4 | correlaciones[-x,x]<(-0.4) ))
library(corrplot)
corrplot::corrplot(correlaciones[correlacionesFuertes,correlacionesFuertes], type="lower", diag = FALSE)


```


```{r}
library(GGally)
## Create data frame indicating missingness by 1
x <- as.data.frame(abs(is.na(train)))
## Select columns with some (but not all) missing values
y <- x[,sapply(x, sd) > 0]

## Create a correlation matrix: Variables missing together have high correlation
cor(y)
cor(train, y, use = "pairwise.complete.obs")
ggcorr(train, method = c("pairwise.complete.obs", "pearson"))
```

###  2.1.4 Outliers: 

Dado el volumen del problema, se llevó a cabo un estudio de outliers univariate básico basado en distancia intercuartil (IQR). Para que este proceso obtenga buenos resultados, se escalaron las variables y se analizaron solo aquellas cuyo dominio es continuo. Los resultados para las variables 1:30 pueden verse en el gráfico 3.5 mientras que las variables 31:70 pueden verse en el gráfico 3.6.

```{r}

```

## 2.1.5 Distribución clases:

Por último, en nuestro proceso de análisis exploratorio, se realizó un gráfico de distribución de variables para comprobar si estamos ante un problema de clases balanceadas o en su defecto no balanceadas. El resultado puede verse en el gráfico 3.7, donde queda constatado que estamos ante un problema donde la clase 0 y la 1 están en clara desventaja por lo que habrá que usar técnicas de oversampling o undersampling

```{r}
library(ggplot2)
ggplot(final, aes(C)) + geom_bar()
```

## 2.2 Preprocesado


### 2.2.1 Imputación de valores perdidos

Uno de los primeros problemas a los que nos hemos enfrentado para comenzar el preprocesamiento de los datos ha sido la existencia de valores perdidos (NAs) en el dataset.

Mice & KNN

El paquete puede usarse para imputar valores perdidos sobre variables categóricas y continuas, usando un algoritmo específico de imputación conocido con el mismo nombre (MICE).

```{r}
library(mice)
library(lattice)
require(robCompositions)
require(mice)
library(Amelia)

data.imputed <- list()
datos <- train

# se determina el numero de instancias sin datos perdidos y con datos
# perdidos. A observar la comodidad de uso de las funciones ncc e nic
completos <- mice::ncc(datos)
incompletos <- mice::nic(datos)
cat("Datos completos: ",completos, " e incompletos: ",incompletos,"\n")
# se realiza la imputacion
m <- 5 #Impute by Average
imputados.pmm <- mice::mice(datos, m=m, meth="pmm")
data.imputed[["pmm"]] <- mice::complete(imputados.pmm)
writeData(data.imputed[["pmm"]], path = "datosFiltrados/", "imputedPmm")

imputados.rf <- mice::mice(datos, m=m, meth="rf", ntree = 3)
data.imputed[["rf"]] <- mice::complete(imputados.rf)
writeData(data.imputed[["rf"]], path = "datosFiltrados/", "imputedRf")

data.imputed[["knnCustom"]] <- imputacionKnnTotal(datos)
writeData(data.imputed[["rf"]], path = "datosFiltrados/", "imputedKnnCustom")

imputados.mean <- mice::mice(datos, m=m, meth="mean") #Impute by Average
data.imputed[["mean"]] <- mice::complete(imputados.mean)
writeData(data.imputed[["mean"]], path = "datosFiltrados/", "imputedMean")


data.imputed[["knn"]] <- robCompositions::impKNNa(datos, primitive=TRUE) #Impute by Predictive Model
writeData(data.imputed[["knn"]], path = "datosFiltrados/", "imputedKnn")

data.imputed[["amelia"]] <- Amelia::amelia(datos,m=1, parallel="multicore",noms="C")
writeData(data.imputed[["amelia"]]$imputations$imp1, path = "datosFiltrados/", "imputedAmelia")
```


### 2.2.3 Outliers

```{r}
data.outlier[["ipf"]] <- ipfFilter(train)
writeData(data.outlier[["ipf"]], path = "datosFiltrados/", "noiseIpf")
```


### 2.2.3 Selección de características

Este apartado va a tratar sobre los procesos y técnicas que hemos seguido para realizar selección de características. La selección de características o atributos consiste en seleccionar un subconjunto relevante de características para poder construir un modelo

```{r}

############
# 4. SMOTE #
############

trainSMOTE <- train

library(unbalanced)
# Aplico SMOTE sobre la clase 0 respecto al resto
instanciasSmote <- unbalanced::ubSMOTE(trainSMOTE[,-75], factor(as.integer(I(train[,75]==0))), perc.over = 200)
# Se unen todas las variables con la clase
instanciasSmote <-cbind(instanciasSmote[[1]], instanciasSmote[[2]])
# Me quedo con las instancias sintéticas para la clase minoritaria 0 que está marcadas como 1
instanciasSmote <- instanciasSmote[which(instanciasSmote[,75]==1),]
# Las convierto a 0
instanciasSmote[,75] <- 0
# Cambio el nombre de la clase a y
names(instanciasSmote)[75] <- "y"
# Añado los SMOTE a train
trainSMOTE <- rbind(trainSMOTE, instanciasSmote)

crossvalidation5(trainSMOTE[,-var[1:25]]) # 0.6523741
prediccionTest(trainSMOTE[,-var[1:25]], test)

##################
# 5. IPF + SMOTE #
##################

trainIPF_SMOTE <- train

# Factorizo la clase para aplicarle IPF
trainIPF_SMOTE[,75] <- factor(trainIPF_SMOTE[,75])
# Le quito las instancias con ruido
# indico que pare a la segunda que no encuentre y que lo haga mediante consenso
trainIPF_SMOTE <- IPF(y ~., trainIPF_SMOTE, consensus = TRUE, s=2)
# Me quedo unicamente con el data.frame limpio
trainIPF_SMOTE <- trainIPF_SMOTE$cleanData

# Aplico SMOTE sobre la clase 0 respecto al resto
instanciasSmote <- unbalanced::ubSMOTE(trainIPF_SMOTE[,-75], factor(as.integer(I(trainIPF_SMOTE[,75]==0))), perc.over = 200)
# Se unen todas las variables con la clase
instanciasSmote <-cbind(instanciasSmote[[1]], instanciasSmote[[2]])
# Me quedo con las instancias sintéticas para la clase minoritaria 0 que está marcadas como 1
instanciasSmote <- instanciasSmote[which(instanciasSmote[,75]==1),]
# Las convierto a 0
instanciasSmote[,75] <- 0
# Cambio el nombre de la clase a y
names(instanciasSmote)[75] <- "y"
# Añado los SMOTE a train
trainIPF_SMOTE <- rbind(trainIPF_SMOTE, instanciasSmote)

crossvalidation5(trainIPF_SMOTE[,-var[1:25]]) # 0.7006897
prediccionTest(trainIPF_SMOTE[,-var[1:25]], test)

##################
# 6. SMOTE + IPF #
##################

trainSMOTE_IPF <- train

# Aplico SMOTE sobre la clase 0 respecto al resto
instanciasSmote <- unbalanced::ubSMOTE(trainSMOTE_IPF[,-75], factor(as.integer(I(trainSMOTE_IPF[,75]==0))), perc.over = 200)
# Se unen todas las variables con la clase
instanciasSmote <-cbind(instanciasSmote[[1]], instanciasSmote[[2]])
# Me quedo con las instancias sintéticas para la clase minoritaria 0 que está marcadas como 1
instanciasSmote <- instanciasSmote[which(instanciasSmote[,75]==1),]
# Las convierto a 0
instanciasSmote[,75] <- 0
# Cambio el nombre de la clase a y
names(instanciasSmote)[75] <- "y"
# Añado los SMOTE a train
trainSMOTE_IPF <- rbind(trainSMOTE_IPF, instanciasSmote)

# Factorizo la clase para aplicarle IPF
trainSMOTE_IPF[,75] <- factor(trainSMOTE_IPF[,75])
# Le quito las instancias con ruido
# indico que pare a la segunda que no encuentre y que lo haga mediante consenso
trainSMOTE_IPF <- IPF(y ~., trainSMOTE_IPF, consensus = TRUE, s=2)
# Me quedo unicamente con el data.frame limpio
trainSMOTE_IPF <- trainSMOTE_IPF$cleanData

crossvalidation5(trainSMOTE_IPF[,-var[1:25]]) # 0.6690093
prediccionTest(trainSMOTE_IPF[,-var[1:25]], test)

##################
# 7. Tomek Links #
##################

trainTL <- train

# Busco las instancias Tomek Links
instanciasTL<- unbalanced::ubTomek(trainTL[,-75], (trainTL[,75]==0))
# Elimino esas instancias de train
trainTL <- trainTL[-instanciasTL$id.rm,]

crossvalidation5(trainTL[,-var[1:25]]) # 0.64294
prediccionTest(trainTL[,-var[1:25]], test)

##########################
# 8. Tomek Links + SMOTE #
##########################

trainTL_SMOTE <- train

# Busco las instancias Tomek Links
instanciasTL<- unbalanced::ubTomek(trainTL_SMOTE[,-75], (trainTL_SMOTE[,75]==0))
# Elimino esas instancias de train
trainTL_SMOTE <- trainTL_SMOTE[-instanciasTL$id.rm,]

# Aplico SMOTE sobre la clase 0 respecto al resto
instanciasSmote <- unbalanced::ubSMOTE(trainTL_SMOTE[,-75], factor(as.integer(I(trainTL_SMOTE[,75]==0))), perc.over = 200)
# Se unen todas las variables con la clase
instanciasSmote <-cbind(instanciasSmote[[1]], instanciasSmote[[2]])
# Me quedo con las instancias sintéticas para la clase minoritaria 0 que está marcadas como 1
instanciasSmote <- instanciasSmote[which(instanciasSmote[,75]==1),]
# Las convierto a 0
instanciasSmote[,75] <- 0
# Cambio el nombre de la clase a y
names(instanciasSmote)[75] <- "y"
# Añado los SMOTE a train
trainTL_SMOTE <- rbind(trainTL_SMOTE, instanciasSmote)

crossvalidation5(trainTL_SMOTE[,-var[1:25]]) # 0.6566631
prediccionTest(trainTL_SMOTE[,-var[1:25]], test)

##########################
# 9. SMOTE + Tomek Links #
##########################

trainSMOTE_TL <- train

# Aplico SMOTE sobre la clase 0 respecto al resto
instanciasSmote <- unbalanced::ubSMOTE(trainSMOTE_TL[,-75], factor(as.integer(I(trainSMOTE_TL[,75]==0))), perc.over = 200)
# Se unen todas las variables con la clase
instanciasSmote <-cbind(instanciasSmote[[1]], instanciasSmote[[2]])
# Me quedo con las instancias sintéticas para la clase minoritaria 0 que está marcadas como 1
instanciasSmote <- instanciasSmote[which(instanciasSmote[,75]==1),]
# Las convierto a 0
instanciasSmote[,75] <- 0
# Cambio el nombre de la clase a y
names(instanciasSmote)[75] <- "y"
# Añado los SMOTE a train
trainSMOTE_TL <- rbind(trainSMOTE_TL, instanciasSmote)

# Busco las instancias Tomek Links
instanciasTL<- unbalanced::ubTomek(trainSMOTE_TL[,-75], (trainSMOTE_TL[,75]==0))
# Elimino esas instancias de train
trainSMOTE_TL <- trainSMOTE_TL[-instanciasTL$id.rm,]

crossvalidation5(trainSMOTE_TL[,-var[1:25]]) # 0.6534006
prediccionTest(trainSMOTE_TL[,-var[1:25]], test)

###########
# 10. ROS #
###########

trainROS <- train

library(ROSE)
# Factorizo la clase
trainROS[,75] <- factor(trainROS[,75])
# Modifico los levels de la clase para aplicar ROS
levels(trainROS[,75]) <- c(0,1,1,1)
instanciasROS <- ROSE::ovun.sample(y ~., trainROS, method = "over")
# Añado a train las instancias ROS de la clase 0
trainROS <- rbind(train, instanciasROS$data[which(instanciasROS$data[,75]==0),])

crossvalidation5(trainROS[,-var[1:25]]) # 0.7229307
prediccionTest(trainROS[,-var[1:25]], test)


#################
# 11. ROS + IPF #
#################

trainROS_IPF <- train

# Factorizo la clase
trainROS_IPF[,75] <- factor(trainROS_IPF[,75])
# Modifico los levels de la clase para aplicar ROS
levels(trainROS_IPF[,75]) <- c(0,1,1,1)
instanciasROS <- ROSE::ovun.sample(y ~., trainROS_IPF, method = "over")
# Añado a train las instancias ROS de la clase 0
trainROS_IPF <- rbind(train, instanciasROS$data[which(instanciasROS$data[,75]==0),])

# Factorizo la clase para aplicarle IPF
trainROS_IPF[,75] <- factor(trainROS_IPF[,75])
# Le quito las instancias con ruido
# indico que pare a la segunda que no encuentre y que lo haga mediante consenso
trainROS_IPF <- IPF(y ~., trainROS_IPF, consensus = TRUE, s=2)
# Me quedo unicamente con el data.frame limpio
trainROS_IPF <- trainROS_IPF$cleanData

crossvalidation5(trainROS_IPF[,-var[1:25]]) # 0.7340467
prediccionTest(trainROS_IPF[,-var[1:25]], test)

#############
# 12. ROS 2 #
#############

train_ROS2 <- train

# Hago ROS de la clase 0 con cada una del resto de manera individual y prestando
# más atención a la clase 1
train_ROS2_1 <- train[which(train_ROS2[,75]==0|train_ROS2[,75]==1),]
train_ROS2_1 <- ROSE::ovun.sample(y ~., train_ROS2_1, method = "over", p=0.5)
train_ROS2_1 <- train_ROS2_1$data
levels(train_ROS2_1) <- c(0,1)

train_ROS2_2 <- train[which(train_ROS2[,75]==0|train_ROS2[,75]==2),]
train_ROS2_2 <- ROSE::ovun.sample(y ~., train_ROS2_2, method = "over", p=0.3)
train_ROS2_2 <- train_ROS2_2$data
levels(train_ROS2_2) <- c(0,2)

train_ROS2_3 <- train[which(train_ROS2[,75]==0|train_ROS2[,75]==1),]
train_ROS2_3 <- ROSE::ovun.sample(y ~., train_ROS2_3, method = "over", p=0.3)
train_ROS2_3 <- train_ROS2_3$data
levels(train_ROS2_3) <- c(0,3)

train_ROS2 <- rbind(train, train_ROS2_1, train_ROS2_2, train_ROS2_3)

crossvalidation5(train_ROS2[,-var[1:25]]) # 0.6478257
prediccionTest(train_ROS2[,-var[1:25]], test)

###################
# 13. ROS 2 + IPF #
###################

train_ROS2_IPF <- train

# Hago ROS de la clase 0 con cada una del resto de manera individual y prestando
# más atención a la clase 1
train_ROS2_1 <- train[which(train_ROS2_IPF[,75]==0|train_ROS2_IPF[,75]==1),]
train_ROS2_1 <- ROSE::ovun.sample(y ~., train_ROS2_1, method = "over", p=0.5)
train_ROS2_1 <- train_ROS2_1$data
levels(train_ROS2_1) <- c(0,1)

train_ROS2_2 <- train[which(train_ROS2_IPF[,75]==0|train_ROS2_IPF[,75]==2),]
train_ROS2_2 <- ROSE::ovun.sample(y ~., train_ROS2_2, method = "over", p=0.3)
train_ROS2_2 <- train_ROS2_2$data
levels(train_ROS2_2) <- c(0,2)

train_ROS2_3 <- train[which(train_ROS2_IPF[,75]==0|train_ROS2_IPF[,75]==1),]
train_ROS2_3 <- ROSE::ovun.sample(y ~., train_ROS2_3, method = "over", p=0.3)
train_ROS2_3 <- train_ROS2_3$data
levels(train_ROS2_3) <- c(0,3)

train_ROS2_IPF <- rbind(train, train_ROS2_1, train_ROS2_2, train_ROS2_3)

# Factorizo la clase para aplicarle IPF
train_ROS2_IPF[,75] <- factor(train_ROS2_IPF[,75])
# Le quito las instancias con ruido
# indico que pare a la segunda que no encuentre y que lo haga mediante consenso
train_ROS2_IPF <- IPF(y ~., train_ROS2_IPF, consensus = TRUE, s=2)
# Me quedo unicamente con el data.frame limpio
train_ROS2_IPF <- train_ROS2_IPF$cleanData

crossvalidation5(train_ROS2_IPF[,-var[1:25]]) # 0.6639876
prediccionTest(train_ROS2_IPF[,-var[1:25]], test)

###########
# 14. ENN #
###########

trainENN <- train

instanciasENN <- unbalanced::ubENN(trainENN[,-75], (trainENN[,75]==0))
trainENN <- trainENN[-instanciasENN$id.rm,]

crossvalidation5(trainENN[,-var[1:25]]) # 0.7550752
prediccionTest(trainENN[,-var[1:25]], test)

##################
# 15. Duplicar 0 #
##################

trainROS_Propio <- train

trainROS_Propio <- rbind(trainROS_Propio, train[which(trainROS_Propio[,75]==0),])

crossvalidation5(trainROS_Propio[,-var[1:25]]) # 0.643618
prediccionTest(trainROS_Propio[,-var[1:25]], test)

#############################
# 16. Duplicar 0 + Random 1 #
#############################

trainROS_Propio <- train

trainROS_Propio <- rbind(trainROS_Propio, train[which(trainROS_Propio[,75]==0),])
trainROS_Propio <- rbind(trainROS_Propio, train[sample(which(trainROS_Propio[,75]==1), length(which(trainROS_Propio[,75]==1))/2.5),]) 

crossvalidation5(trainROS_Propio[,-var[1:25]]) # 0.6458915
prediccionTest(trainROS_Propio[,-var[1:25]], test)

# Gráfico para ver el acierto sobre train (Mejora el acierto de la clase 0 pero se reducen en la dos)
prediccionesFinal <- prediccionTest(trainROS_Propio[,-var[1:25]], train)

ggplot2::ggplot()+
  geom_col(aes(x=0:3, y=as.data.frame(table(train[,75]))[,2], fill="Original"), alpha=.8) + 
  geom_col(aes(x=0:3, y=as.data.frame(diag(table(train[,75], prediccionesFinal)))[,1], fill="Predicciones"), alpha=.8) +
  scale_fill_discrete("Datos") +
  labs(x = "Clase", y = "Valores")

```

## Modelos 

```{r}
data <- train
data$C <- as.factor(data$C)
trees <- crear_arbol(datos = data, "C")
print_diagnostic(trees, trees[[const$sets]])
```



